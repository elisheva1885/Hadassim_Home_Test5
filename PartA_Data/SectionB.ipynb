{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "81d3388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "def from_excel_to_csv(filePath):\n",
    "    df = pd.read_excel(f\"{filePath}.xlsx\")\n",
    "    df.to_csv(f\"{filePath}.csv\", index=False)\n",
    "    return 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3c1421c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_file_by_ending(filePath, endingType):\n",
    "    readers = {\n",
    "        'csv': pd.read_csv,\n",
    "        'xlsx': pd.read_excel,\n",
    "        'json': pd.read_json,\n",
    "        'parquet': pd.read_parquet,\n",
    "    }\n",
    "\n",
    "    if endingType not in readers:\n",
    "        raise ValueError(f\"Unsupported file type: {endingType}\")\n",
    "\n",
    "    df = readers[endingType](f\"{filePath}.{endingType}\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d973643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clear_non_valid_dates(df):\n",
    "    df['timestamp']  = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    df_valid_dates = df[df['timestamp'].notna()]\n",
    "    return df_valid_dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24958a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b412af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_duplicated_dates(df):\n",
    "    df_grouped = df.groupby('timestamp', as_index=False)['value'].sum()\n",
    "    return df_grouped\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf6eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4a145458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_non_numeric_values(df):\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    df = df.dropna(subset=['value'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37bdbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ed43bbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def average_for_hour(df, path, endingType):\n",
    "    df['start_time'] = df['timestamp'].dt.floor('H')  \n",
    "    hour_average = df[['start_time', 'value']].groupby('start_time').mean()\n",
    "#     writers = {\n",
    "#         'csv': lambda df, path: df.to_csv(path, index=True),\n",
    "#         'xlsx': lambda df, path: df.to_excel(path, index=False),\n",
    "#         'json': lambda df, path: df.to_json(path, orient='records', lines=True),\n",
    "#         'parquet': lambda df, path: df.to_parquet(path, index=False),\n",
    "#     }\n",
    "#     if endingType not in writers:\n",
    "#         raise ValueError(f\"Unsupported file type: {endingType}\")\n",
    "\n",
    "    # Create the file path and save the result\n",
    "#     file_path = f\"{path}/hour_average.{endingType}\"\n",
    "#     writers[endingType](hour_average, file_path)\n",
    "    hour_average.to_csv(f\"{path}/hour_average.csv\")\n",
    "# def average_for_hour(df, path, endingType):\n",
    "#     # Calculate the hourly average\n",
    "#     df['start_time'] = df['timestamp'].dt.floor('H')  \n",
    "#     hour_average = df[['start_time', 'value']].groupby('start_time').mean()\n",
    "\n",
    "#     # Save the result based on the file type (endingType)\n",
    "#     writers = {\n",
    "#         'csv': lambda df, path: df.to_csv(path, index=True),\n",
    "#         'xlsx': lambda df, path: df.to_excel(path, index=False),\n",
    "#         'json': lambda df, path: df.to_json(path, orient='records', lines=True),\n",
    "#         'parquet': lambda df, path: df.to_parquet(path, index=False),\n",
    "#     }\n",
    "\n",
    "#     # Check if the file type is valid\n",
    "#     if endingType not in writers:\n",
    "#         raise ValueError(f\"Unsupported file type: {endingType}\")\n",
    "\n",
    "#     # Create the file path and save the result\n",
    "#     file_path = f\"{path}/hour_average.{endingType}\"\n",
    "#     writers[endingType](hour_average, file_path)\n",
    "#     print(f\"Saved the average hourly data to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053dd420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9114b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "eee427d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_df_by_days(df):\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    rows_for_day = df[['timestamp','date', 'hour','value']].groupby(['date']).count()\n",
    "    df_sorted = df.sort_values('timestamp') \n",
    "    return df_sorted[['timestamp', 'value']], rows_for_day['hour']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4d1e7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_to_files_byDays(df, rows_range, path, endingType):\n",
    "\n",
    "    writers = {\n",
    "        'csv': lambda df, path: df.to_csv(path, index=True),\n",
    "        'xlsx': lambda df, path: df.to_excel(path, index=False),\n",
    "        'json': lambda df, path: df.to_json(path, orient='records', lines=True),\n",
    "        'parquet': lambda df, path: df.to_parquet(path, index=False),\n",
    "    }\n",
    "\n",
    "    if endingType not in writers:\n",
    "        raise ValueError(f\"Unsupported file type: {endingType}\")\n",
    "\n",
    "    index = 0;\n",
    "    for j in range(rows_range.shape[0]):\n",
    "        df_to_file = df[index:index+rows_range[j]]\n",
    "        index += rows_range[j]\n",
    "        file_name = f\"{path}/time_series{j + 1}.{endingType}\"\n",
    "        writers[endingType](df_to_file, file_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c0478377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def read_files(readingPath, index , endingType):\n",
    "    readers = {\n",
    "        'csv': pd.read_csv,\n",
    "        'xlsx': pd.read_excel,\n",
    "        'json': pd.read_json,\n",
    "        'parquet': pd.read_parquet,\n",
    "    }\n",
    "\n",
    "    if endingType not in readers:\n",
    "        raise ValueError(f\"Unsupported file type: {endingType}\")\n",
    "\n",
    "    df_form_file = readers[endingType](f\"{readingPath}{index+1}.{endingType}\")\n",
    "    df_form_file['timestamp'] = pd.to_datetime(df_form_file['timestamp'], errors='coerce')\n",
    "    df_form_file['start_time'] = df_form_file['timestamp'].dt.floor('H')\n",
    "\n",
    "    file_result = df_form_file[['start_time','value']].groupby(['start_time']).mean()\n",
    "    return file_result\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f35b0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def read_from_files_and_union_the_averages(path , endingType):\n",
    "    union_df = pd.DataFrame()\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        dfs = [executor.submit(read_files, f\"{path}/time_series\", index  , endingType) for index in range(30)]\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    df_list = [future.result() for future in dfs]\n",
    "    union_df = pd.concat(df_list, ignore_index=False)\n",
    "    return union_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "20beea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_in_file(df,filePath):\n",
    "#     writers = {\n",
    "#         'csv': lambda df, path: df.to_csv(path, index=True),\n",
    "#         'xlsx': lambda df, path: df.to_excel(path, index=False),\n",
    "#         'json': lambda df, path: df.to_json(path, orient='records', lines=True),\n",
    "#         'parquet': lambda df, path: df.to_parquet(path, index=False),\n",
    "#     }\n",
    "\n",
    "#     if endingType not in writers:\n",
    "#         raise ValueError(f\"Unsupported file type: {endingType}\")\n",
    "    df.to_csv(f\"{filePath}/filesResult.csv\")\n",
    "#     writers[endingType](df, path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e145378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_timestamp_file_hour_value(filePath , writingPath , endingType):\n",
    "    if(endingType=='xlsx'):\n",
    "        endingType = from_excel_to_csv(filePath)\n",
    "    df = read_file_by_ending(filePath, endingType)\n",
    "    df_valid_dates = clear_non_valid_dates(df) \n",
    "    df_clear_dup_dated = clear_duplicated_dates(df_valid_dates)\n",
    "    df_valid_values = remove_non_numeric_values(df_clear_dup_dated)\n",
    "    average_for_hour(df_valid_values, writingPath , endingType)\n",
    "    df_sorted, rows_for_day = group_df_by_days(df_valid_values)\n",
    "    split_df_to_files_byDays(df_sorted, rows_for_day, writingPath, endingType)\n",
    "    union_df = read_from_files_and_union_the_averages(writingPath , endingType)\n",
    "    save_result_in_file(union_df , writingPath)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e086aa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\משפחת ספראי\\AppData\\Local\\Temp\\ipykernel_11000\\2885839199.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_time'] = df['timestamp'].dt.floor('H')\n",
      "C:\\Users\\משפחת ספראי\\AppData\\Local\\Temp\\ipykernel_11000\\4064657661.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['hour'] = df['timestamp'].dt.hour\n",
      "C:\\Users\\משפחת ספראי\\AppData\\Local\\Temp\\ipykernel_11000\\4064657661.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = df['timestamp'].dt.date\n",
      "C:\\Users\\משפחת ספראי\\AppData\\Local\\Temp\\ipykernel_11000\\2885839199.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_time'] = df['timestamp'].dt.floor('H')\n",
      "C:\\Users\\משפחת ספראי\\AppData\\Local\\Temp\\ipykernel_11000\\4064657661.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['hour'] = df['timestamp'].dt.hour\n",
      "C:\\Users\\משפחת ספראי\\AppData\\Local\\Temp\\ipykernel_11000\\4064657661.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = df['timestamp'].dt.date\n"
     ]
    }
   ],
   "source": [
    "from_timestamp_file_hour_value( \"./files/time_series\",\"./files/time_serieses\", 'xlsx')\n",
    "from_timestamp_file_hour_value( \"./files/time_series\",\"./files/time_serieses\", 'parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95d3f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\משפחת ספראי\\AppData\\Local\\Temp\\ipykernel_11000\\2766379585.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_time'] = df['timestamp'].dt.floor('H')  # Round down to the start of the hour\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
